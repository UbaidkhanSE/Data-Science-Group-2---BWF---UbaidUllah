{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795288c5-7acc-4d79-ac0a-27bba8f7713d",
   "metadata": {},
   "source": [
    "# **Deep Learning with TensorFlow/Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db46ef-fe2c-4541-b0ed-0f5c4964e2e2",
   "metadata": {},
   "source": [
    "## **Problem Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec42173-df4c-4bfc-9f2c-54c29684ae99",
   "metadata": {},
   "source": [
    "The goal of this project is to build and train a neural network classifier to predict whether a breast cancer tumor is malignant or benign based on various features extracted from medical imaging. This classification task is a binary classification problem where the model needs to classify the tumors into two categories:\n",
    "\n",
    "Malignant (M): Tumors that are cancerous and require immediate medical attention.\n",
    "Benign (B): Tumors that are non-cancerous and typically less urgent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "892dc3ec-84f1-4633-bb5c-768ca1a1be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None  \n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "968fa371-df4c-48b3-a362-5c382742f0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 32)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset from the UCI ML repository\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\", \n",
    "                 sep=\",\", header=None)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b591482-9ae2-4494-8cf7-fa33c580934a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9       10       11      12      13     14      15        16       17  \\\n",
       "0  0.14710  0.2419  0.07871  1.0950  0.9053  8.589  153.40  0.006399  0.04904   \n",
       "1  0.07017  0.1812  0.05667  0.5435  0.7339  3.398   74.08  0.005225  0.01308   \n",
       "2  0.12790  0.2069  0.05999  0.7456  0.7869  4.585   94.03  0.006150  0.04006   \n",
       "3  0.10520  0.2597  0.09744  0.4956  1.1560  3.445   27.23  0.009110  0.07458   \n",
       "4  0.10430  0.1809  0.05883  0.7572  0.7813  5.438   94.44  0.011490  0.02461   \n",
       "\n",
       "        18       19       20        21     22     23      24      25      26  \\\n",
       "0  0.05373  0.01587  0.03003  0.006193  25.38  17.33  184.60  2019.0  0.1622   \n",
       "1  0.01860  0.01340  0.01389  0.003532  24.99  23.41  158.80  1956.0  0.1238   \n",
       "2  0.03832  0.02058  0.02250  0.004571  23.57  25.53  152.50  1709.0  0.1444   \n",
       "3  0.05661  0.01867  0.05963  0.009208  14.91  26.50   98.87   567.7  0.2098   \n",
       "4  0.05688  0.01885  0.01756  0.005115  22.54  16.67  152.20  1575.0  0.1374   \n",
       "\n",
       "       27      28      29      30       31  \n",
       "0  0.6656  0.7119  0.2654  0.4601  0.11890  \n",
       "1  0.1866  0.2416  0.1860  0.2750  0.08902  \n",
       "2  0.4245  0.4504  0.2430  0.3613  0.08758  \n",
       "3  0.8663  0.6869  0.2575  0.6638  0.17300  \n",
       "4  0.2050  0.4000  0.1625  0.2364  0.07678  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f20300e8-e87f-4e2f-8f96-f20f220cf8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>2.873000</td>\n",
       "      <td>4.885000</td>\n",
       "      <td>21.980000</td>\n",
       "      <td>542.200000</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.052790</td>\n",
       "      <td>0.078950</td>\n",
       "      <td>0.029840</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0           2           3           4            5   \\\n",
       "count  5.690000e+02  569.000000  569.000000  569.000000   569.000000   \n",
       "mean   3.037183e+07   14.127292   19.289649   91.969033   654.889104   \n",
       "std    1.250206e+08    3.524049    4.301036   24.298981   351.914129   \n",
       "min    8.670000e+03    6.981000    9.710000   43.790000   143.500000   \n",
       "25%    8.692180e+05   11.700000   16.170000   75.170000   420.300000   \n",
       "50%    9.060240e+05   13.370000   18.840000   86.240000   551.100000   \n",
       "75%    8.813129e+06   15.780000   21.800000  104.100000   782.700000   \n",
       "max    9.113205e+08   28.110000   39.280000  188.500000  2501.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  569.000000   \n",
       "mean     0.096360    0.104341    0.088799    0.048919    0.181162    0.062798   \n",
       "std      0.014064    0.052813    0.079720    0.038803    0.027414    0.007060   \n",
       "min      0.052630    0.019380    0.000000    0.000000    0.106000    0.049960   \n",
       "25%      0.086370    0.064920    0.029560    0.020310    0.161900    0.057700   \n",
       "50%      0.095870    0.092630    0.061540    0.033500    0.179200    0.061540   \n",
       "75%      0.105300    0.130400    0.130700    0.074000    0.195700    0.066120   \n",
       "max      0.163400    0.345400    0.426800    0.201200    0.304000    0.097440   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  569.000000   \n",
       "mean     0.405172    1.216853    2.866059   40.337079    0.007041    0.025478   \n",
       "std      0.277313    0.551648    2.021855   45.491006    0.003003    0.017908   \n",
       "min      0.111500    0.360200    0.757000    6.802000    0.001713    0.002252   \n",
       "25%      0.232400    0.833900    1.606000   17.850000    0.005169    0.013080   \n",
       "50%      0.324200    1.108000    2.287000   24.530000    0.006380    0.020450   \n",
       "75%      0.478900    1.474000    3.357000   45.190000    0.008146    0.032450   \n",
       "max      2.873000    4.885000   21.980000  542.200000    0.031130    0.135400   \n",
       "\n",
       "               18          19          20          21          22          23  \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  569.000000   \n",
       "mean     0.031894    0.011796    0.020542    0.003795   16.269190   25.677223   \n",
       "std      0.030186    0.006170    0.008266    0.002646    4.833242    6.146258   \n",
       "min      0.000000    0.000000    0.007882    0.000895    7.930000   12.020000   \n",
       "25%      0.015090    0.007638    0.015160    0.002248   13.010000   21.080000   \n",
       "50%      0.025890    0.010930    0.018730    0.003187   14.970000   25.410000   \n",
       "75%      0.042050    0.014710    0.023480    0.004558   18.790000   29.720000   \n",
       "max      0.396000    0.052790    0.078950    0.029840   36.040000   49.540000   \n",
       "\n",
       "               24           25          26          27          28  \\\n",
       "count  569.000000   569.000000  569.000000  569.000000  569.000000   \n",
       "mean   107.261213   880.583128    0.132369    0.254265    0.272188   \n",
       "std     33.602542   569.356993    0.022832    0.157336    0.208624   \n",
       "min     50.410000   185.200000    0.071170    0.027290    0.000000   \n",
       "25%     84.110000   515.300000    0.116600    0.147200    0.114500   \n",
       "50%     97.660000   686.500000    0.131300    0.211900    0.226700   \n",
       "75%    125.400000  1084.000000    0.146000    0.339100    0.382900   \n",
       "max    251.200000  4254.000000    0.222600    1.058000    1.252000   \n",
       "\n",
       "               29          30          31  \n",
       "count  569.000000  569.000000  569.000000  \n",
       "mean     0.114606    0.290076    0.083946  \n",
       "std      0.065732    0.061867    0.018061  \n",
       "min      0.000000    0.156500    0.055040  \n",
       "25%      0.064930    0.250400    0.071460  \n",
       "50%      0.099930    0.282200    0.080040  \n",
       "75%      0.161400    0.317900    0.092080  \n",
       "max      0.291000    0.663800    0.207500  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44020178-d7e0-43b2-8040-18a775c06a83",
   "metadata": {},
   "source": [
    "## **Explore the target variable**\n",
    "Let's explore the dependent variable. Its a string column, referring to the 'M' and 'B' targt categories. Before feeding the data in a Neural Network, it will require one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ba9e94d-6143-4bf8-aa04-2de404795a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M', 'B'}\n",
      "no. classes: 2\n"
     ]
    }
   ],
   "source": [
    "print(set(df[df.columns[1]]))\n",
    "print('no. classes: ' + str(len(set(df[df.columns[1]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32eacaf7-68ed-46f2-b780-b7c140d4a8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 2)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "classification = pd.get_dummies(df[df.columns[1]])\n",
    "print(classification.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0402c0-0883-4d3c-81e1-20a310ee84f4",
   "metadata": {},
   "source": [
    "I obtained a target dataframe, called classification, that contains the one-hot encoded version of my dependent binary variable. Now I can isolate the explanatory variables in my dataframe df. In order to do that I'll drop columns 0 and 1: the first is an index, the second is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8c642df-3f3b-4f11-8542-841bb75dbdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2      3       4       5        6        7       8        9       10  \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        11      12      13     14      15        16       17       18  \\\n",
       "0  0.07871  1.0950  0.9053  8.589  153.40  0.006399  0.04904  0.05373   \n",
       "1  0.05667  0.5435  0.7339  3.398   74.08  0.005225  0.01308  0.01860   \n",
       "2  0.05999  0.7456  0.7869  4.585   94.03  0.006150  0.04006  0.03832   \n",
       "3  0.09744  0.4956  1.1560  3.445   27.23  0.009110  0.07458  0.05661   \n",
       "4  0.05883  0.7572  0.7813  5.438   94.44  0.011490  0.02461  0.05688   \n",
       "\n",
       "        19       20        21     22     23      24      25      26      27  \\\n",
       "0  0.01587  0.03003  0.006193  25.38  17.33  184.60  2019.0  0.1622  0.6656   \n",
       "1  0.01340  0.01389  0.003532  24.99  23.41  158.80  1956.0  0.1238  0.1866   \n",
       "2  0.02058  0.02250  0.004571  23.57  25.53  152.50  1709.0  0.1444  0.4245   \n",
       "3  0.01867  0.05963  0.009208  14.91  26.50   98.87   567.7  0.2098  0.8663   \n",
       "4  0.01885  0.01756  0.005115  22.54  16.67  152.20  1575.0  0.1374  0.2050   \n",
       "\n",
       "       28      29      30       31  \n",
       "0  0.7119  0.2654  0.4601  0.11890  \n",
       "1  0.2416  0.1860  0.2750  0.08902  \n",
       "2  0.4504  0.2430  0.3613  0.08758  \n",
       "3  0.6869  0.2575  0.6638  0.17300  \n",
       "4  0.4000  0.1625  0.2364  0.07678  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop([df.columns[0], df.columns[1]], axis=1)   # drop the target variable from df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09ab37e3-ea13-42f8-a851-cfd0882aa293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the shape is:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8bdce-369d-4611-b081-4c49c3308cc9",
   "metadata": {},
   "source": [
    "Before training the model, I turn both explanatory and target data into numpy objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "22963fa0-af82-47c0-9955-4bc43897b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.values\n",
    "classification = classification.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0dc70357-7179-45e9-a746-ed713660ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this case, I uniform the datatypes to float64\n",
    "classification = classification.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b7baf9-7f24-47be-80de-36e27247ac19",
   "metadata": {},
   "source": [
    "## **Train-Test split**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d38f68-ce66-440d-9c23-808aa31d5788",
   "metadata": {},
   "source": [
    "In an actual ML job, you would split your dataset in Train, Validation and Testsets. However, this is just an example on how to implement and run a Neural Network, so I'll skip that part and will split the data in train and test only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "863614e9-db0d-4684-a548-cef7eee0cfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (426, 30)\n",
      "y_train shape: (426, 2)\n",
      "\n",
      "X_test shape: (143, 30)\n",
      "y_test shape: (143, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, classification, test_size=0.25, random_state=173)\n",
    "\n",
    "print('X_train shape: ' + str(X_train.shape) + '\\ny_train shape: ' + str(y_train.shape))\n",
    "print('\\nX_test shape: ' + str(X_test.shape) + '\\ny_test shape: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8ff5eb-5a3e-4687-8541-4d8b0768ea8d",
   "metadata": {},
   "source": [
    "Scaling the variables must happen after the train-test split. That is because the test set must be scaled using the parameters of the training set: in real world cases you don't know what data you'll get from training, therefore this is the only way to truly understand the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3efbc09d-01d7-4d55-bf18-94f56fc465ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the variables using Z-scores\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68da093-5b76-4260-8e2a-c1b0ee256ed3",
   "metadata": {},
   "source": [
    "## **Neural Network architecture**\n",
    "Since the network is not very deep, and the number of parameters is relatively small, I can employ more \"demanding\" (and performing) activation functions. In this case, I choose ELU (Exponential Linear Unit) activations. A softmax function is then applied at the end, so that the attribution of classes (M/B) is shrinked into probabilities.\n",
    "\n",
    "Additionally, I apply dropout in order to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ea86688f-ab7d-4fe6-8c60-731d31607965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.activations import elu, softmax\n",
    "\n",
    "# Architecture\n",
    "n_input = X_train.shape[1]\n",
    "n_hidden1 = 30\n",
    "n_hidden2 = 20\n",
    "n_hidden3 = 15\n",
    "n_output = y_train.shape[1]\n",
    "\n",
    "# set dropout probability\n",
    "dropout_prob = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6bdc8a-1ab3-4610-8353-391a0c46dace",
   "metadata": {},
   "source": [
    "he definition of a model in TensorFlow 2.0 follows the syntax of Keras' Sequential() models.\n",
    "\n",
    "Each layer is defined by the Dense() function, taking as inputs: the previous layer, the number of nodes, and the activation function (it can actually take a lor of additional arguments, but I'll not review them here). The input layer also requires a definition of the input data shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e2e3c84-73c0-47a4-bccc-a5e837fbc39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ubaid-khan\\anaconda3\\envs\\MytestEnv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    Dense(n_input, input_shape = (n_input,), activation = elu),   # Input layer\n",
    "    \n",
    "    Dense(n_hidden1, activation = elu), # hidden layer 1\n",
    "    Dropout(dropout_prob),     \n",
    "    \n",
    "    Dense(n_hidden2, activation = elu), # hidden layer 2\n",
    "    Dropout(dropout_prob), \n",
    "    \n",
    "    Dense(n_hidden3, activation = elu), # hidden layer 3\n",
    "    Dropout(dropout_prob), \n",
    "    \n",
    "    Dense(n_output, activation = softmax)  # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebb97b36-da05-49fa-aa3c-2bac6cc12fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">620</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_114 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_111 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m930\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_112 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m930\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_61 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_113 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m620\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_62 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_114 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m315\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_63 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_115 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m32\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,827</span> (11.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,827\u001b[0m (11.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,827</span> (11.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,827\u001b[0m (11.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971c836-4d59-4680-bac2-4ce20762ae20",
   "metadata": {},
   "source": [
    "## **Implementation of full-Batch Gradient Descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c149d4b-e89f-4777-82a0-1f2b58ddc249",
   "metadata": {},
   "source": [
    "his is Gradient Descent in its simplest form, in which the whole bunch (erhm, batch) of training data is fed into the network at each iteration.\n",
    "\n",
    "(In a following Notebook I will show the implementation of a more powerful technique: Mini-Batch Gradient Descent.)\n",
    "\n",
    "In order to train the model, I neeed to define a loss function (that Gradient Descent will minimize), an accuracy metrics (in oreder to monitor the model's performance through the epochs) and an optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "309fd661-8d90-43b4-8f75-f95f3a5c4e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss: Binary cross-entropy is made for \n",
    "bce_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Binary Accuracy (expressed in the [0,1] interval)\n",
    "accuracy = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "# Adam Optimizer (what you'll need 99.99% of the time)\n",
    "optimizer = tf.optimizers.Adam(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d3f9c-7387-476d-ba69-dfbb24b7bfc8",
   "metadata": {},
   "source": [
    "There are at least two ways to train a Neural Network in TensorFlow 2.0. The first is using Keras, by calling:\n",
    "\n",
    "model.compile(optimizer, loss, metrics)\n",
    "The other is to use pure TensorFlow's eager execution method, which is what I'll do here. In TensorFlow 1.x what you had to do was to create a computational graph (with placeholders instead of actual data), and then running it in a tf.Session(). Eager execution instead is the TensorFlow's variant of imperative programming: operations are evaluated immediately without building graphs, and run instantly. Eager execution makes code is easier to debug, and your whole script much less verbose and easier to read (now it looks pretty much like canonical Python). Another reason why Google's engineers changed TensorFlow so profoudly is that symbolic programming was not so popular (and they want TensorFlow to keep competing against pyTorch, which gained a lot in popularity recently).\n",
    "\n",
    "The reason why I employ eager execution is that I think it gives you more control on model training, and a better control of the output. Also, it forces you to better understand how training a Neural Network works.\n",
    "\n",
    "The fundamental element of training a Network in eager execution is represented by tf.GradientTape(). This object calculates and stores the gradient of the loss function at each iteration of the training operation. Once you generate a GradientTape, you can call the .gradient() argument to get the actual gradient (i.e. the first derivative of the loss function). Later, you feed this values into an optimizer using the .apply_gradients argument that updates the Network's trainable variables (the very act of \"learning\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a762816a-aab0-4be3-add3-6e6a7e065f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.\tTraining Loss: 0.36438382,\tAccuracy: 0.9859155\n",
      "200.\tTraining Loss: 0.20687912,\tAccuracy: 0.9906103\n",
      "300.\tTraining Loss: 0.16598918,\tAccuracy: 0.9906103\n",
      "400.\tTraining Loss: 0.15731598,\tAccuracy: 0.9906103\n",
      "500.\tTraining Loss: 0.12298764,\tAccuracy: 0.9929578\n",
      "600.\tTraining Loss: 0.11679145,\tAccuracy: 0.9929578\n",
      "700.\tTraining Loss: 0.11510241,\tAccuracy: 0.9929578\n",
      "800.\tTraining Loss: 0.114337265,\tAccuracy: 0.9929578\n",
      "900.\tTraining Loss: 0.11391637,\tAccuracy: 0.9929578\n",
      "1000.\tTraining Loss: 0.113657385,\tAccuracy: 0.9929578\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "###  TRAINING\n",
    "\n",
    "# save loss and accuracy improvements through epochs\n",
    "loss_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "# iterate for 1000 epochs\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    # GratientTape is what I need in order to calculate gradients of the loss function\n",
    "    with tf.GradientTape() as tape:\n",
    "        # take current binary cross-entropy (bce_loss)\n",
    "        current_loss = bce_loss(model(X_train), y_train)\n",
    "    \n",
    "    # HERE THE ACTUAL TRAINING HAPPENS:\n",
    "    # Update weights based on the gradient of the loss function\n",
    "    gradients = tape.gradient(current_loss, model.trainable_variables)    # get the gradient of the loss function\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))  # update the weights\n",
    "    \n",
    "    # save current loss in its history vector\n",
    "    loss_history.append(current_loss.numpy())\n",
    "    \n",
    "    # save current accuracy in its history vector\n",
    "    accuracy.update_state(y_train, model(X_train))  # this computes the accuracy and stores it\n",
    "    current_accuracy = accuracy.result().numpy()  # save its result as numpy object\n",
    "    accuracy_history.append(current_accuracy)\n",
    "    \n",
    "    # In order to monitor progress, I will print loss and accuracy scores every 100 epochs\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(str(epoch+1) + '.\\tTraining Loss: ' + str(current_loss.numpy()) + ',\\tAccuracy: ' + str(current_accuracy))\n",
    "    \n",
    "    accuracy.reset_state()  # reset the state of accuracy object for next iteration\n",
    "\n",
    "print('\\nTraining complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb88a9c-e802-4b08-8c01-14b70d17233e",
   "metadata": {},
   "source": [
    "## **Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b33c8767-68f5-4e38-ac18-03719c633025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using plt.subplot I can show paired loss and accuracy\n",
    "\n",
    "plt.figure(figsize = (15, 4))  # adjust figures size\n",
    "plt.subplots_adjust(wspace=0.2)  # adjust distance between plots\n",
    "\n",
    "# loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss_history)\n",
    "plt.title('Loss History')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Binary Cross-Entropy')\n",
    "\n",
    "# accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracy_history)\n",
    "plt.title('Accuracy History')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cacab80-91b1-4472-bd2b-5a36813f31e2",
   "metadata": {},
   "source": [
    "## **Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dfb5e1b8-a2c6-49d1-b472-dc846920fe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "177f44c6-89ff-4ada-a30e-de4ec521c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs vector containing the value of the class with the highest predicted probability\n",
    "prediction = np.argmax(prediction, axis=1)\n",
    "\n",
    "# do it also for test data, i.e. reverse one-hot encoding and get a vector of 0-1 values\n",
    "testdata = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d42d5262-e360-4d05-aca1-e12a0aac9278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86  0]\n",
      " [ 3 54]]\n"
     ]
    }
   ],
   "source": [
    "# Now I can plot the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "CM = confusion_matrix(prediction, testdata)\n",
    "print(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2755d530-c5e7-4577-a873-8bd88ab2d5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9790209790209791\n"
     ]
    }
   ],
   "source": [
    "# Accuracy = sum of the diagonal / sum of the whole matrix\n",
    "\n",
    "print('Test Accuracy: ' + str(np.sum(np.diag(CM)) / np.sum(CM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "246f81fb-c2c9-44b9-a49b-c615a3be24ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn\n",
    "\n",
    "seaborn.heatmap(CM, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c29e1-2852-4b7d-8faa-a1e01a53c9b2",
   "metadata": {},
   "source": [
    "# **Task 33: Regression Problem with Tensoeflow/keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7fd561b8-3cfe-4a5e-a0db-2bd1dfb4066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7c466ca-ad03-4dfe-b5b6-9ce9ae882e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a977cf-29ba-4df4-87e6-40a1667474e7",
   "metadata": {},
   "source": [
    "## **Data Normalization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e25ced4e-b1b4-408a-a2f3-4980df0166ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "train_data -= mean\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be4791-35c7-4840-ae32-c71c7134a8f1",
   "metadata": {},
   "source": [
    "## **Model Architecture:**\n",
    "-The model is a sequential neural network with multiple dense (fully connected) layers.\n",
    "\n",
    "-The input layer has the same number of neurons as the number of features in the data.\n",
    "\n",
    "-Three hidden layers are defined with 128, 64, and 32 neurons respectively, each using the ReLU activation function.\n",
    "\n",
    "-Dropout layers are added to prevent overfitting by randomly setting a fraction (20%) of input units to 0 during training.\n",
    "\n",
    "-The output layer has a single neuron with no activation function since this is a regression task.\n",
    "\n",
    "-Compilation: The model is compiled with the RMSprop optimizer, Mean Squared Error (MSE) as the loss function, and Mean Absolute Error (MAE) as an additional metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3876414b-9803-4a3e-8efb-d4f6120bd4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Input(shape=(train_data.shape[1],)),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=RMSprop(), loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b192e969-53ad-4d5a-9648-a50b43019eb0",
   "metadata": {},
   "source": [
    "## **K-Fold Cross-Validation**\n",
    "\n",
    "K-Fold Cross-Validation: The training data is split into 4 folds. This allows the model to train on 3 folds and validate on the remaining fold, ensuring the model's performance is not biased toward a specific partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b767193-a5eb-4c80-98be-f1e0f2b2cc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold #0\n",
      "Processing fold #1\n",
      "Processing fold #2\n",
      "Processing fold #3\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 500\n",
    "all_mae_histories = []\n",
    "\n",
    "for i in range(k):\n",
    "    print(f\"Processing fold #{i}\")\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=16, verbose=0)\n",
    "    mae_history = history.history[\"val_mae\"]\n",
    "    all_mae_histories.append(mae_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea62eb94-9bac-4a4a-9e05-299b8d18ae0f",
   "metadata": {},
   "source": [
    "## **Plotting the history of successive mean K-fold validation scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e00b1cc-121e-489a-a78c-ec806febac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
    "\n",
    "# Plot validation scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation MAE\")\n",
    "plt.title(\"Validation MAE over Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c9494-dc31-4224-aae3-de9917b927b7",
   "metadata": {},
   "source": [
    "## **Plot validation scores excluding the first 10 data points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df3b9b-b6ec-4bd7-9e2b-b1d3106e902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_mae_history = average_mae_history[10:]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(truncated_mae_history) + 1), truncated_mae_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation MAE\")\n",
    "plt.title(\"Validation MAE over Epochs (Excluding First 10 Epochs)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b570f0e-1cb5-4cff-8cd8-1fe3474c3c4f",
   "metadata": {},
   "source": [
    "## **Train the final  model  and make prediction** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae67b33-7fe2-47a2-9b22-3a1569ac2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "history = model.fit(train_data, train_targets,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=130, batch_size=16, verbose=0)\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "print(f\"Test MSE: {test_mse_score}, Test MAE: {test_mae_score}\")\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = model.predict(test_data)\n",
    "mse = mean_squared_error(test_targets, predictions)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Sample prediction:\", predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c4a43-bb18-4baf-bcea-908018d1b278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MytestEnv)",
   "language": "python",
   "name": "mytestenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
